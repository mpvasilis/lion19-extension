# Phase 1 Experiments Summary

## Overview
Successfully executed Phase 1 passive learning for **4 different benchmark variants**, each with mock overfitted constraints consistent with E+ but not part of the true target model.

## Date
October 20, 2025

## Benchmarks Executed

### 1. Regular Sudoku (`sudoku`)
**Description**: Standard 9x9 Sudoku with AllDifferent constraints on rows, columns, and 3x3 blocks.

**Configuration**:
- Positive Examples (E+): 5
- Mock Overfitted Constraints: 4

**Results**:
- **Detected AllDifferent**: 27 (rows, columns, blocks) âœ“
- **Overfitted AllDifferent**: 4 (scope 3-3)
- **Total CG**: 31 constraints
- **Binary Bias**: 19,440 â†’ 2,856 (after pruning with E+)
- **Target AllDifferent**: 27
- **Output**: `phase1_output/sudoku_phase1.pkl`

**Status**: âœ“ SUCCESS

---

### 2. Greater-Than Sudoku (`sudoku_gt`)
**Description**: 9x9 Sudoku with additional greater-than constraints between adjacent cells (Futoshiki-style).

**Configuration**:
- Positive Examples (E+): 5
- Mock Overfitted Constraints: 6

**True Constraints (added to target)**:
- Standard AllDifferent (rows, columns, blocks)
- 5 horizontal greater-than constraints
- 5 vertical greater-than constraints

**Mock Overfitted Constraints (NOT in target)**:
- Diagonal pattern: `AllDifferent([grid[0,0], grid[1,1], grid[2,2]])`
- Ordering mocks: `grid[0,0] < grid[1,1] < grid[2,2]`
- Corner cells: `AllDifferent([grid[0,0], grid[0,8], grid[8,0], grid[8,8]])`
- Additional arbitrary greater-than constraints

**Results**:
- **Detected AllDifferent**: 27 (standard Sudoku structure)
- **Overfitted AllDifferent**: 6 (scope 3-4)
- **Total CG**: 33 constraints
- **Binary Bias**: 19,440 â†’ 3,096 (after pruning with E+)
- **Target AllDifferent**: 27
- **Output**: `phase1_output/sudoku_gt_phase1.pkl`

**Status**: âœ“ SUCCESS

---

### 3. Exam Timetabling Variant 1 (`examtt_v1`)
**Description**: Smaller exam timetabling instance with aggressive day-level constraints and specific slot patterns.

**Configuration**:
- Semesters: 6
- Courses per Semester: 5
- Slots per Day: 6
- Days for Exams: 10
- Total Variables: 30
- Positive Examples (E+): 5
- Mock Overfitted Constraints: 5

**True Constraints (target)**:
- AllDifferent on all exam slots
- AllDifferent on exam days per semester
- Count constraints limiting exams per day

**Mock Overfitted Constraints (NOT in target)**:
1. First two semesters must have all exams on different days (overly restrictive AllDifferent)
2. Last semester exams must be in last 3 days (inequality constraints)
3. Day 3 must have exactly 2 exams (Count == 2, too specific)
4. Middle semester courses redundant AllDifferent
5. Sum constraint on first semester slots (arbitrary pattern)

**Results**:
- **Detected AllDifferent**: 0 (pattern detection didn't match exam structure)
- **Overfitted AllDifferent**: 5 (scope 4-7)
- **Total CG**: 5 constraints
- **Binary Bias**: 2,610 â†’ 469 (after pruning with E+)
- **Target AllDifferent**: 7
- **Output**: `phase1_output/examtt_v1_phase1.pkl`

**Status**: âœ“ SUCCESS

**Note**: Pattern detection is optimized for grid-based problems (like Sudoku) and didn't detect the exam timetabling structure. This is expected - Phase 2 will need to learn these from active queries.

---

### 4. Exam Timetabling Variant 2 (`examtt_v2`)
**Description**: Larger exam timetabling instance with cross-semester patterns and ordering constraints.

**Configuration**:
- Semesters: 8
- Courses per Semester: 7
- Slots per Day: 8
- Days for Exams: 12
- Total Variables: 56
- Positive Examples (E+): 5
- Mock Overfitted Constraints: 6

**True Constraints (target)**:
- AllDifferent on all exam slots
- AllDifferent on exam days per semester
- Count constraints limiting exams per day

**Mock Overfitted Constraints (NOT in target)**:
1. First course of each semester ordered by semester index (ordering chain)
2. Even/odd semesters disjoint day sets (complex AllDifferent on subset)
3. Middle 3 days must have exactly 5 exams each (Count == 5, very specific)
4. Diagonal pattern across semesters and courses (AllDifferent on diagonal)
5. Last 2 semesters in first half of schedule (inequality constraints)
6. Specific day must have >= 3 exams (Count constraint)

**Results**:
- **Detected AllDifferent**: 0 (pattern detection didn't match exam structure)
- **Overfitted AllDifferent**: 6 (scope 3-6)
- **Total CG**: 6 constraints
- **Binary Bias**: 9,240 â†’ 2,114 (after pruning with E+)
- **Target AllDifferent**: 9
- **Output**: `phase1_output/examtt_v2_phase1.pkl`

**Status**: âœ“ SUCCESS

**Note**: Similar to variant 1, pattern detection didn't recognize the exam structure. The overfitted constraints include diverse patterns testing Phase 2's ability to handle complex cross-variable relationships.

---

## Summary Statistics

| Benchmark | Variables | CG Size | Detected | Overfitted | Binary Bias (Pruned) | Status |
|-----------|-----------|---------|----------|------------|---------------------|---------|
| sudoku | 81 | 31 | 27 | 4 | 2,856 | âœ“ |
| sudoku_gt | 81 | 33 | 27 | 6 | 3,096 | âœ“ |
| examtt_v1 | 30 | 5 | 0 | 5 | 469 | âœ“ |
| examtt_v2 | 56 | 6 | 0 | 6 | 2,114 | âœ“ |

## Key Observations

### 1. Pattern Detection Effectiveness
- **Sudoku variants**: Pattern detection works perfectly for grid-based structures, detecting all 27 AllDifferent constraints (9 rows + 9 columns + 9 blocks).
- **Exam Timetabling variants**: Pattern detection is not optimized for exam timetabling's complex multi-dimensional structure. This is expected and highlights the need for Phase 2.

### 2. Mock Overfitted Constraints
All benchmarks successfully generated mock constraints that:
- âœ“ Are consistent with all 5 positive examples (E+)
- âœ“ Are NOT part of the true target model
- âœ“ Should be rejected in Phase 2 through interactive refinement
- âœ“ Test different aspects of the HCAR methodology:
  - Sudoku: Small scope (3 variables) spurious patterns
  - Sudoku GT: Diagonal and corner patterns, ordering chains
  - Exam V1: Day-level restrictions, specific counts, sum constraints
  - Exam V2: Cross-semester patterns, complex orderings, multiple count constraints

### 3. Binary Bias Pruning
Bias pruning with E+ effectively reduced the search space:
- Sudoku: 85.3% reduction (19,440 â†’ 2,856)
- Sudoku GT: 84.1% reduction (19,440 â†’ 3,096)
- Exam V1: 82.0% reduction (2,610 â†’ 469)
- Exam V2: 77.1% reduction (9,240 â†’ 2,114)

This demonstrates that even with just 5 examples, substantial pruning is possible while maintaining soundness (no true constraints were removed).

## Next Steps

These Phase 1 outputs are ready for Phase 2 processing:

1. **Load pickle files** containing:
   - `CG`: Candidate global constraints (detected + overfitted)
   - `B_fixed`: Pruned binary bias
   - `E+`: Positive examples
   - `variables`: CPMpy variables
   - `initial_probabilities`: Informed priors (0.8 for detected, 0.3 for overfitted)

2. **Run Phase 2** (Query-Driven Refinement with Disambiguation):
   - Use ML classifier to assign probabilities
   - Generate violation queries (COP)
   - Disambiguate false constraints through isolation
   - Apply probabilistic belief updates
   - Accept high-confidence constraints
   - Reject low-confidence constraints and generate repairs

3. **Expected Phase 2 Behavior**:
   - **Sudoku**: Should accept all 27 detected, reject 4 overfitted
   - **Sudoku GT**: Should accept all 27 detected AllDifferent + 10 greater-than constraints, reject 6 overfitted
   - **Exam V1**: Should reject all 5 overfitted, learn true structure interactively
   - **Exam V2**: Should reject all 6 overfitted, learn true structure interactively

## Files Created

```
benchmarks_global/
â”œâ”€â”€ sudoku_greater_than.py          (NEW: Greater-than Sudoku variant)
â”œâ”€â”€ exam_timetabling_variants.py    (NEW: Two exam variants with mocks)
â””â”€â”€ __init__.py                     (UPDATED: Export new benchmarks)

phase1_output/
â”œâ”€â”€ sudoku_phase1.pkl               (27 detected + 4 mock = 31 CG)
â”œâ”€â”€ sudoku_gt_phase1.pkl            (27 detected + 6 mock = 33 CG)
â”œâ”€â”€ examtt_v1_phase1.pkl            (0 detected + 5 mock = 5 CG)
â””â”€â”€ examtt_v2_phase1.pkl            (0 detected + 6 mock = 6 CG)

*.py
â”œâ”€â”€ phase1_passive_learning.py      (UPDATED: Support new benchmarks)
â””â”€â”€ run_phase1_experiments.py       (NEW: Batch runner for all variants)
```

## Research Significance

These experiments provide diverse test cases for validating the HCAR methodology:

1. **Over-fitting Detection**: All benchmarks include mock constraints that will test Phase 2's ability to detect and reject over-fitted patterns.

2. **Robustness Testing**: The variety of constraint types (AllDifferent, Count, ordering, Sum) tests the generality of the disambiguation and repair mechanisms.

3. **Scalability**: From 30 to 81 variables, from 5 to 33 candidate constraints - tests HCAR across different problem sizes.

4. **Pattern Complexity**: From simple grid structures to complex multi-dimensional scheduling problems.

These Phase 1 outputs are ready for the next stage of HCAR experimentation! ðŸŽ¯

